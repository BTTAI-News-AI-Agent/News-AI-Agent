"""Milestone 5: BART and LLaMA Summarization

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1raMiSkP9gHk9qW-qpAxYnC81xbFKqlWh
"""

import os
import pandas as pd
import nltk
import torch
import textwrap
from transformers import (
    pipeline,
    BartForConditionalGeneration,
    BartTokenizer,
)
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

nltk.download('punkt')
nltk.download('punkt_tab')

# ---- Load Data ----
DATA_PATH = os.path.expanduser("~/Downloads/combined_golden_set.csv")

if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"Dataset not found at {DATA_PATH}")

df = pd.read_csv(DATA_PATH)
print(f"Loaded dataset with {len(df)} entries.\nColumns: {list(df.columns)}\n")
sample_text = df["article_text"].iloc[0]


# -------------------------------------------------------------------
# Summarization Functions
# -------------------------------------------------------------------
def text_summarizer_bart(text, verbose=False):
    """
    Summarize text using BART (CNN/DailyMail version).
    """
    model_name = "facebook/bart-large-cnn"
    model = BartForConditionalGeneration.from_pretrained(model_name)
    tokenizer = BartTokenizer.from_pretrained(model_name)

    inputs = tokenizer.encode("summarize: " + text, return_tensors="pt", max_length=1024, truncation=True)
    summary_ids = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, 
                                 num_beams=4, early_stopping=True)

    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    if verbose:
        print(textwrap.fill(summary, width=70))
    return summary


def text_summarizer_bart_xsum(text, verbose=False):
    """
    Summarize text using BART XSum (BBC-style one-sentence summaries).
    """
    summarizer = pipeline("summarization", model="facebook/bart-large-xsum")
    result = summarizer(text, max_length=60, min_length=10, do_sample=False)
    summary_text = result[0]['summary_text']
    if verbose:
        print(textwrap.fill(summary_text, width=70))
    return summary_text

# -------------------------------------------------------------------
# Run Sample Text
# -------------------------------------------------------------------
# print("\n--- SAMPLE ARTICLE ---\n")
# print(textwrap.fill(sample_text[:700], width=70))
# print("\n--- BART-XSum Summary ---\n")
# summary = text_summarizer_bart_xsum(sample_text, verbose=True)

def format_input(example):
    example["input_text"] = (
        "Answer this question: " + example["question"] + "\n\n"
        "Article:\n" + example["article_text"]
    )
    example["target_text"] = example["golden_summary"]
    return example

# -------------------------------------------------------------------
# Evaluation Using BLEU (BART CNN vs BART XSum)
# -------------------------------------------------------------------

from rouge_score import rouge_scorer
scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)


print("\n--- BLEU Evaluation: BART-CNN vs BART-XSum ---\n")

if "golden_summary" not in df.columns:
    raise KeyError("Expected column 'golden_summary' not found in dataset.")

smooth = SmoothingFunction().method1

summarizer_cnn = pipeline("summarization",
                          model="facebook/bart-large-cnn",
                          device=0)

summarizer_xsum = pipeline("summarization",
                           model="facebook/bart-large-xsum",
                           device=0)

scores_cnn, scores_xsum = [], []

for i, row in df.head(10).iterrows():
    formatted_input = format_input(row)["input_text"]
    input_preview = textwrap.fill(formatted_input[:400], width=90)
    headline = "A slump in profitability at luxury car maker Mercedes has prompted a big drop in profits at parent DaimlerChrysler."
    headline_preview = textwrap.fill(headline, width=90)

    print(f"\n{'='*100}")
    print(f"ARTICLE {i} PREVIEW:\n{input_preview}\n")


    # --- Generate summaries ---
    summary_cnn = summarizer_cnn(formatted_input,
                                 max_length=120, min_length=30,
                                 do_sample=False)[0]["summary_text"]

    summary_xsum = summarizer_xsum(formatted_input,
                                   max_length=60, min_length=10,
                                   do_sample=False)[0]["summary_text"]

    # --- Compute BLEU ---
    reference = nltk.word_tokenize(row["golden_summary"].lower())
    candidate_cnn = nltk.word_tokenize(summary_cnn.lower())
    candidate_xsum = nltk.word_tokenize(summary_xsum.lower())

    bleu_cnn = sentence_bleu([reference], candidate_cnn, smoothing_function=smooth)
    bleu_xsum = sentence_bleu([reference], candidate_xsum, smoothing_function=smooth)

    bleu_xsum_headline = sentence_bleu([reference], nltk.word_tokenize(headline.lower()), smoothing_function=smooth)

    scores_cnn.append(bleu_cnn)
    scores_xsum.append(bleu_xsum)

    # compute ROUGE-L scores
    rouge_cnn = scorer.score(row["golden_summary"], summary_cnn)
    rouge_xsum = scorer.score(row["golden_summary"], summary_xsum)

    # --- Print Results ---
    print(f"BART-CNN Summary:\n{textwrap.fill(summary_cnn, width=90)}\n")
    print(f"BART-XSum Summary:\n{textwrap.fill(summary_xsum, width=90)}\n")
    print(f"Expected (Golden Summary):\n{textwrap.fill(row['golden_summary'], width=90)}\n")
    print(f"BLEU - CNN: {bleu_cnn:.4f} | XSum: {bleu_xsum:.4f}")
    print(f"BLEU - Headline: {bleu_xsum_headline:.4f}\n")

    print(f"ROUGE-L - CNN: {rouge_cnn['rougeL'].fmeasure:.4f} | XSum: {rouge_xsum['rougeL'].fmeasure:.4f}\n")

    print(f"Headline:\n{headline_preview}\n")
    print("="*100)

# # --- Average Scores ---
print(f"\nAverage BLEU (BART-CNN): {sum(scores_cnn)/len(scores_cnn):.4f}")
print(f"Average BLEU (BART-XSum): {sum(scores_xsum)/len(scores_xsum):.4f}")

